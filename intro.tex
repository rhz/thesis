% \input{epigraph}
% \noindent
\section{Historical background}

In the history of natural sciences,
there has been two main approaches to describe dynamical systems,
which I call here
\emph{kinetics} and \emph{thermodynamics}.
Loosely speaking, in the kinetic approach the system is
described by the positions and momenta of each particle.
This approach goes all the way back to
Newton's laws of motion~\citep{newton}.
Intuitively, it is a ``ground'' description in the sense that
it is as explicit and detailed as possible.
If a (classical) mechanical system has $N$ particles
then a state of the system is described by
a vector in $\RR^{2 \cdot 3 \cdot N}$.
% Regarding the role of forces in Newtonian mechanics:
% Interactions producing a change of momentum on a particle
% that can be measured independently do not interact between them
% and thus the resulting derivative of the momentum (force)
% is just the sum of the forces as measured independently.

On the other hand,
the thermodynamic approach shows how
all information about the change of the system in time
is contained in the energy function (for conservative systems).
Given a set of states $\states$ for the system,
an energy function $E: \states \to \RR$ maps a state to its energy.
In this way a state is described by a single scalar
regardless of how many particles it comprises.
Naturally, this approach endowed the description of
a dynamical system in classical mechanics
with a remarkable conciseness, simplicity and elegance.
It first appeared in the work of
\citet{lagrange2} and \citet{hamilton},
and has been subsequently used as the basis for most of modern physics.
Once in possession of the energy function,
the kinetic description (\ie the equations of motion)
can then be derived from it.
However the converse is not true:
in general a kinetic description might not have an energy function
from which it can be derived \citep{santilli},
partly because of non-conservative (\eg dissipative) forces.
Obtaining an energy function from the equations of motion
is called the \emph{inverse problem} in classical mechanics
and it was first attended to by \citet{helmholtz}.
Both the direct and the inverse problem are the interest of this thesis.
Note that this approach has been given the name `thermodynamic'
not because of thermodynamics,
the science that studies the dynamics of heat and temperature,
but because of the protagonical role of the energy
in driving the system's evolution.
Certainly, there are connections to thermodynamics
that will be highlighted as they arise.

Half a century after Hamilton's work
researchers like Maxwell, Boltzmann, and Gibbs
applied the ideas of classical mechanics to \emph{atoms}
in order to describe physical properties of matter like pressure,
the capacity to transfer heat, and others.
This body of work came to be known as \emph{statistical mechanics}
and was used to explain Brownian motion by \citet{einstein-brownian},
which after its experimental verification \citep{perrin}
settled the debate about the existence of atoms.
This work however did not attempt to explain
the chemical interactions and reactions that molecules undergo.
That would have to wait yet half a century
for the axiomatisation of probability theory by \citet{kolmogorov}
and the further developments by \citet{doob} and \citet{feller},
who, among others, established the theoretical framework
for continuous-time Markov chains (CTMCs).
Below you can find the definitions for a CTMC
and its infinitesimal generator that will be used in this thesis.
In particular, we work with time-homogeneous CTMCs.

\begin{definition}%[Infinitesimal generator]
  An \emph{infinitesimal generator} $\qm$
  on an at most countable set of states $\states$
  is an $\states \times \states$ matrix
  with elements $q_{ij} \in \RR$, $i,j \in \states$
  such that $0 \leqslant q_{ij} < \infty$ when $i \neq j$
  and $q_{ii} = - \sum_{j \neq i} q_{ij} < \infty$.
\end{definition}

The infinitesimal generator plays the role of
the time derivative of the transition probabilities at time $0$
and induces the evolution of a probabilistic state
according to the Kolmogorov backward equation,
\begin{equation}
  \label{eq:transition-function}
  \ddt P(t) = Q P(t), \quad P(0) = I
\end{equation}
where $P(t)$ is the $\states \times \states$ matrix
with elements $p_{ij}(t) \in \RR$ the probability that
we were in state $i$ at time $0$ and are in state $j$ at time $t$.
% transition probability from state $i$ to $j$ at time $t$.
When the infinitesimal generator is stable and conservative
there is a unique minimal solution to \eqn{transition-function}
\citep{anderson}.
We shall work with this type of infinitesimal generators
and assume there is a transition function $P(t)$
whenever we have an infinitesimal generator $\qm$ and vice versa.

Given a \pmf $s(0)$ on $\states$ (seen as a row vector)
as an initial probabilistic state,
the probability distribution $s(t)$ after time $t$
is given by $s(t) = s(0) P(t)$.
% We can obtain the time derivative of this distribution
% from \eqn{transition-function}.
% % $s_i(t)$ that the Markov chain is in state $i$ at time $t$.
% In coordinate form, we have
% \begin{equation} % TODO: is this equation correct?
%   \label{eq:prob-deriv}
%   \ddt s_i(t) = \sum_{j \in \states} q_{ji} s_j(t)
% \end{equation}
We say the infinitesimal generator is \emph{irreducible}
if every state is reachable regardless of the initial state,
\ie $p_{ij}(t) > 0$ for all $i,j \in \states$
and some $t \geqslant 0$.

\begin{definition}[CTMC]%[continuous-time Markov chain]
  A \emph{continuous-time Markov chain} is a tuple
  $\tuple{\states, s(0), \qm}$ with
  $\states$ an at most countable set of states,
  $s(0)$ a \pmf on $\states$
  representing the initial probabilistic state and
  $\qm$ the infinitesimal generator of the Markov chain.
  % The Markov chain can be presented as a time-indexed family
  % of random variables $X_t$.
\end{definition}

% TODO: Am I here introducing something after using/mentioning it?
An important property of CTMCs for the present work is that of
\emph{time reversibility}, also known as \emph{detailed balance},
which we introduce below.

\begin{definition}[detailed balance]
  An infinitesimal generator $\qm$ on $\states$
  is said to be \emph{time reversible} iff
  there is a \pmf $\ip$ on $\states$ such that
  \begin{equation}
    \label{eq:detailed-balance}
    \ip_i q_{ij} = \ip_j q_{ji}
  \end{equation}
  for all $i,j \in \states$.
  Then $\qm$ is said to have \emph{detailed balance}
  with respect to $\ip$.
\end{definition}

A related property is that of
having an \emph{invariant} probability measure.

\begin{definition}
  A \pmf $\ip$ on $\states$ is
  \emph{invariant} for an infinitesimal generator $\qm$
  iff $\ip \qm = 0$, \ie
  \[ -\ip_i q_{ii} = \ip_i \sum_{j \neq i} q_{ij}
                  = \sum_{j \neq i} \ip_j q_{ji} \]
  In other words,
  whenever the action of $\qm$ on it does not change it.
\end{definition}

The relationship between % these two properties
detailed balance and having an invariant probability measure
is established by the following lemma.

\begin{lemma}
  Suppose the infinitesimal generator $\qm$
  has detailed balance with respect to $\ip$.
  Then $\ip$ is invariant for $\qm$.
\end{lemma}
\begin{proof}
  From \eqn{detailed-balance} we obtain
  \[ \sum_{i \in \states} \ip_i q_{ij} =
     \sum_{i \in \states} \ip_j q_{ji} = -\ip_j q_{jj}, \]
  as $\sum_{i \in \states} q_{ji} = -q_{jj}$ for any fixed state $j$.
\end{proof}

Moreover, we would like to know when this invariant
probability measure is realised by the Markov chain.

\begin{definition}[ergodicity]
  An infinitesimal generator $\qm$ is \emph{ergodic} when
  there is a probability measure $\ip$ on $\states$ such that
  \[ \lim_{t \to \infty} P_{ij}(t) = \ip_j \]
  for all $i,j \in \states$.
\end{definition}

This is equivalent to say that the Markov chain
will converge to the probability measure $\ip$
regardless of the initial state $s(0)$.

\begin{lemma}
  Suppose the infinitesimal generator $\qm$ is irreducible
  and has an invariant probability measure $\ip$.
  Then $\qm$ is ergodic and converges to $\ip$.
\end{lemma}

The proof for this lemma can be found in part 2 of theorem 1.6
in chapter 5 of Anderson's book (\cite*[][pages 160--161]{anderson}).
CTMCs have a strong kinetic flavour as they describe
stochastic processes in terms of probability flows
happening at a certain rate.
They are the ``ground'' description in the stochastic world
and all approaches to describe these processes
are interpreted in terms of them.

It is natural to wonder then how the thermodynamic approach
looks like in the stochastic world.
It turns out the energy function has a very clear interpretation
in this setting, namely, that of defining the probability $\ip_i$
that the system finds itself in state $i \in \states$ as follows.
\begin{equation}
  \label{eq:energy}
  \ip_i = \frac{e^{-E(i)}}{\sum_{j \in \states} e^{-E(j)}}
\end{equation}
This is known as the \emph{Boltzmann distribution}.
Usually the energy is divided by $kT$ the product of
the Boltzmann constant $k$ and the temperature $T$.
However, we can omit this term by expressing the energy
in units of $1/(kT)$.
Note also that (i) \eqn{energy} defines the energy function
uniquely only up to an additive constant
given the probability distribution $\ip$,
that is, if we change the energy of each state by adding
a fixed constant we obtain the same probability distribution $\ip$;
and (ii) by convention the sign of the energy is inverted
so lower energies represent more favourable states.

The next question is how do we construct a CTMC
from an energy function.
What else do we need?
Clearly, we need to know the state space $\states$.
Also, unlike in classical mechanics,
we would need to know which transitions between states are possible
since there are no assumptions of continuity on $\states$.
The first formulation to shed light on this problem
was proposed by \citet{metropolis}.
The algorithm asks for an energy function and an \emph{a priori},
one-step transition probability matrix
that is assumed to be symmetric,
\ie that for any two states $i,j \in \states$
the elements $a_{ij}$ and $a_{ji}$ of the matrix are equal.
This matrix plays the role of the infinitesimal generator in the
discrete-time setting (\ie where time is indexed by the naturals)
and each element $a_{ij}$ denotes the probability that
we choose to jump to state $j$ when we are at state $i$.
Hence $\sum_{j \in \states} a_{ij} = 1$ for any fixed $i$
and we write $a_{i-}$ for this probability distribution.
The algorithm has been generalised to the case of asymmetric
a priori probability matrices by \citet{hastings}.

The construction gives a discrete-time Markov chain that
converges to the probability distribution $\ip$ in \eqn{energy}.
For the sake of simplicity we present here
only the original formulation.
The algorithm then works as follows.
Given any state $i \in \states$ we pick a neighbour state $j$
at random according to the probability distribution $a_{i-}$.
We evaluate the energy function at $i$ and $j$
to compute $\Delta E = E(j)-E(i)$ and proceed with the transition
with probability $1$ if $\Delta E < 0$ and
probability $e^{-\Delta E}$ if $\Delta E > 0$.
Otherwise we stay at state $i$.
In both cases time (a natural number) is increased by 1.

To see that $\ip$ as defined in \eqn{energy} is the invariant
probability distribution of the discrete-time Markov chain
we show that it has (the discrete-time version of)
detailed balance with respect to $\ip$.
The probability $p_{ij}$ of jumping from $i$ to $j$ is
a combination of the a priori probability and
the probability of accepting that transition,
which depends on $\Delta E$.
\[ p_{ij} = a_{ij}\; \min(1, e^{-\Delta E}) \]
By taking the ratio of $p_{ij}$ and $p_{ji}$ we have
\[ \frac{p_{ij}}{p_{ji}} =
   \frac{a_{ij}\; \min(1, e^{E(i)-E(j)})}{
         a_{ji}\; \min(1, e^{E(j)-E(i)})} =
   \frac{\min(1, e^{E(i)-E(j)})}{
         \min(1, e^{E(j)-E(i)})} \]
since $a_{ij} = a_{ji}$ by symmetry of the
a priori transition probability matrix.
Suppose $E(i)-E(j) > 0 > E(j)-E(i)$,
\[ \frac{p_{ij}}{p_{ji}} = e^{E(i)-E(j)}
     = \frac{e^{-E(j)}}{e^{-E(i)}} = \frac{\ip_{j}}{\ip_{i}} \]
It is easy to see that when
$E(j)-E(i) > 0 > E(i)-E(j)$ we obtain the same equation.
Hence the discrete-time Markov chain has detailed balance
with respect to $\ip$ as defined in \eqn{energy}.
Provided the a priori transition probability matrix
makes it possible to reach any state from any other state,
the Markov chain will converge to $\ip$ as $t \to \infty$.

The Metropolis-Hastings algorithm can be generalised
to the continuous-time case \citep{diaconis}.
However, the algorithm require us to either
(i) compute the energy of all states to obtain the probabilities
$p_{ij}$ (or transition rates $q_{ij}$ in the continuous-time case),
or (ii) do rejection sampling, as outlined above.
Option (i) can be very time-consuming when $\states$ is large
% or the evaluation of the energy function is expensive.
or it's costly to evaluate the energy function.
Option (ii) can be inefficient when the rejection rate is high.
For these reasons we explore an alternative method in this thesis.
We partition the state space in regions of equal energy
and group transitions according to these regions.
This is made possible by assuming extra structure on $\states$
(to be introduced in \sct{kappa}).

Let us go back to the stochastic modelling of
chemical interactions mentioned above.
The theory of CTMCs allows one to frame
the dynamics of chemical reaction systems.
However, since the number of molecules of a species
is a priori unbounded and thus $\states$ is infinite,
one would like to have a way to express these systems
in a finite and simple form.
A language that could do this
came to be in the work of \citet{petri}.
This language, later called \emph{Petri nets},
sees reactions as transformations of
multisets of chemical species.

\begin{definition}
  A \emph{multiset} $M$ over a set $X$ is a map from $X$ to
  the naturals assigning to each element $x \in X$
  the number of copies $M(x) \in \NN$ of that element
  in the multiset.
\end{definition}

There is a natural partial order $\leqslant$ on multisets over $X$.
We say $M \leqslant N$ if for each element $x \in X$,
$M(x) \leqslant N(x)$.
We write $\MM(X)$ for the set of all multisets over $X$.


\begin{definition}
  Given a set of species $\species$,
  a \emph{reaction} $r$ is a pair $\tuple{L,R}$
  with $L$ and $R$ multisets over $\species$.
  We refer to $L$ and $R$ as the left- and right-hand side of $r$.
  % and write $L \to R$ for the reaction.
\end{definition}

\begin{definition}%[PN]%[Petri net]
  A \emph{Petri net} is a pair $\tuple{\species, \reactions}$ with
  a set of species $\species$ and a set of reactions $\reactions$.
\end{definition}

A state of a Petri net is a multiset over $\species$,
usually called a \emph{marking}.
A reaction can occur in a given state $M$ only if
its left-hand side $L \leqslant M$.

\begin{definition}
  A \emph{match} $m$ of the left-hand side $L$ of a reaction
  on a state $M$ is an injective function from $L$ to $M$,
  \ie a map that identifies each copy of $a \in \species$ in $L$
  with a copy of $a$ in $M$.
\end{definition}

We write $\matches{L}{M}$ for the set of matches from $L$ to $M$.
From this definition we have that the number of matches
$\abs{\matches{L}{M}}$ from $L$ to $M$ is
\[ \abs{\matches{L}{M}} = \prod_{a \in \species} \binom{L(a)}{M(a)} \]
A reaction is said to be elementary iff its rate is
proportional to the number of matches of its left-hand side.
This is known as the \emph{law of mass action} in chemistry.
Here we consider only elementary reactions.

Petri nets can be given a stochastic interpretation
in terms of a CTMC.
Given a Petri net $\tuple{\species, \reactions}$,
an initial marking $M_0$ and
a kinetic map $k: \reactions \to \RR^+$ that assigns
kinetic rates $k(r)$ to reactions $r \in \reactions$,
we construct a CTMC $\tuple{\states, s(0), \qm}$ as follows.
\begin{align*}
  \states &{} = \MM(\species) \\
  s(0)(x) &{} = \begin{cases}
    1 \quad\text{if } x = M_0 \\
    0 \quad\text{if } x \neq M_0
  \end{cases} \\
  q_{MN} &{} = \sum_{\tuple{L,R} \in \reactions} n_{MN}(L,R)
\end{align*}
with
\begin{equation*}
  n_{MN}(L,R) = \left\{\begin{array}{ll}
    \abs{\matches{L}{M}} & \text{if } M - L + R = N \\
    0 & \text{otherwise}
  \end{array}\right.
\end{equation*}

The physical validity of this stochastic approach
and the physical conditions under which
it can be used has been argued by \citet{gillespie76}.
Interestingly, \citet{et2} have solved
the \emph{direct} and \emph{inverse} problem for Petri nets,
that is, the problem of constructing a Petri net
from an energy function on $\states$ and vice versa.

Petri nets have limitations when we take into consideration
what happens inside molecules in a chemical reaction.
The chemical transformation taking place amounts to
a change in the way electrons are shared by atoms
resulting in a relocation of chemical bonds.
In other words, (non-radioactive) reactions are all about
the binding and unbinding of atoms,
how they establish connections and break them.
This is poorly captured by a change of species,
as it is modelled by Petri nets.
A consequence of this lack of a formal representation for
molecular bonds is that certain systems of chemical reactions
cannot be described in a finite way using Petri nets,
\eg unbounded polymerisation
(think of a molecular chain that can always attach new links).

Recently,
a formal language to describe biochemical interactions
using rewriting rules,
where molecules not just react but also can bind other molecules
has been proposed by \citet{danoslaneve2002a}.
In the next section we introduce this language, called Kappa,
% and some of its properties,
keeping in mind that we want to address
the \emph{direct} and \emph{inverse} problem mentioned above,
namely, the problem of generating a set of rewriting rules
from an energy function and vice versa.


\section{Kappa}
\label{sec:kappa}

Kappa represents interactions among proteins,
nucleic acids and other biomolecules as
connections in a biomolecular network.
In these networks, nodes stand for the biomolecules
while connections represent transient molecular bonds
(\eg non-covalent interactions like hydrogen bonds).
This network is constantly changing as molecules
travel and interact with other molecules in a cell,
which is viewed as the constant destruction and creation
of the connections that make up the network.

Due to spatial constraints,
molecules can physically interact with
just so many other molecules at once.
Exactly how many will depend on multiple factors like
the size of the two interacting molecules and
the region where they come in contact.
These regions, known in molecular biology by the names of domains,
motifs or binding sites, are simply called \emph{sites} in Kappa.
Any such site can bind at most one other site at a time.
These sites belong to the nodes of the graph,
which Kappa calls \emph{agents}.
In the same way a molecule is of a certain species,
agents can be of different types.
These types also live in a network,
a static network which represents the ``network of possibilities''.
It tell us which sites a site \emph{can} bind
instead of what is actually bound to at a given moment.

To make these ideas formal we will use
the category-theoretical approach % presented by \citet{kappadpo}.
introduced in the work of \citet{kappadpo}.
We first define the networks where types live and then
use them as a basis to construct the actual biomolecular networks.%
% build on them to construct the actual biomolecular networks.%
\footnote{Below we use the words graph and edge
  as synonyms for network and connection.}

\begin{definition}%[site graph]
  A \emph{site graph} $G$ consists of
  a finite set of agents $\agents_G$,
  a finite set of sites $\sites_G$,
  a map $\sitemap_G: \sites_G \to \agents_G$
  that assigns sites to agents
  and a symmetric edge relation $\edges_G$ on $\sites_G$.
\end{definition}

The pair $\sites_G$, $\edges_G$ form an undirected graph.
Clearly, the definition of site graphs does not impose
a bound on the number of connections a site can have.
% it just lists the possibilities.
Indeed there is no restriction at all so far.
This is the network where types live.

Sites not in the domain of $\edges_G$ are said to be \emph{free}.
One says $G$ is \emph{realisable} iff
(i) no site has an edge to itself and
(ii) sites have at most one incident edge.
Each realisable site graph represents a state
in which our biomolecular network can be.
Note however that it contains no typing information.
We can give a type to each agent and site in the graph
by assigning to it an agent and site in the type graph.
More precisely,
we need a map from a realisable site graph to a site graph.
Below we introduce such maps.

\begin{flushleft}
\begin{minipage}{.66\linewidth}
\begin{definition}
  A \emph{homomorphism} $h: G \to G'$ of site graphs is
  a pair of functions, $h_\sites: \sites_G \to \sites_{G'}$
  and $h_\agents: \agents_G \to \agents_{G'}$, such that
  for all $s,s' \in \sites_G$ we have
  (i) $h_\agents(\sitemap_G(s)) = \sitemap_{G'}(h_\sites(s))$
  and (ii) if $s \mathbin{\edges_G} s'$ then
  $h_\sites(s) \mathbin{\edges_{G'}} h_\sites(s')$.
\end{definition}
\end{minipage}
\begin{minipage}{.3\linewidth}
\begin{flushright}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=30pt,column sep=30pt] {
      \sites_G & \sites_{G'} \\
      \agents_G & \agents_{G'} \\};
    \draw[hom] (m-1-1) -- node[above] {$h_\sites$} (m-1-2);
    \draw[hom] (m-2-1) -- node[below] {$h_\agents$} (m-2-2);
    \draw[hom] (m-1-1) -- node[left] {$\sitemap_G$} (m-2-1);
    \draw[hom] (m-1-2) -- node[right] {$\sitemap_{G'}$} (m-2-2);
  \end{tikzpicture}
\end{flushright}
\end{minipage}
\end{flushleft}

Put simply, homomorphisms preserve site ownership and connections.
The diagram to the right is the corresponding
commutative diagram in the category $\Set$
of sets and total functions
to condition (i) in the definition.
We call the homomorphism $h: G \to C$ a contact map over $C$
iff $G$ is realisable and refer to $C$ as the contact graph.
Contact maps act as the typing map mentioned above.

Site graphs and homomorphisms form a category $\SG$.
The composition of two homomorphisms
$h_1: G_1 \to G_2$ and $h_2: G_2 \to G_3$
is a homomorphism $h: G_1 \to G_3$ with
$h_\sites = h_{2,\sites} \comp h_{1,\sites}$ and
$h_\agents = h_{2,\agents} \comp h_{1,\agents}$.
It is easy to see that composition defined in this way is associative.
The identity arrow $\id_G: G \to G$ in $\SG$ is defined
using the identity functions of the corresponding sets.

A homomorphism $h: G \to G'$ is an \emph{embedding} iff
(i) $h_\agents$ and $h_\sites$ are injective and
(ii) if $s$ is free in $G$, so is $h_\sites(s)$ in $G'$.
Injectivity of $h_\agents$ and $h_\sites$ implies that
whenever $h: G \to G'$ is an embedding and $G'$ is realisable
then $G$ is also realisable.

\begin{wrapfigure}[4]{r}{0.28\textwidth}
  \vspace{-2.4em}
  \begin{center}
    \begin{tikzpicture}
      \matrix (m) [matrix of math nodes,row sep=20pt,column sep=20pt] {
        G & & G' \\
        & C & \\};
      \draw[hom] (m-1-1) -- node[above] {$h$} (m-1-3);
      \draw[hom] (m-1-1) -- node[below left] {$g$} (m-2-2);
      % \draw[hom] (m-1-3) -- node[below right] {$g'$} (m-2-2);
      \draw[hom] (m-1-3) -- node[below right] (g) {\phantom{$g$}}
                 (m-2-2);
      \node[anchor=south] at (g.south) {$g'$};
    \end{tikzpicture}
  \end{center}
\end{wrapfigure}

An embedding $h: G \to G'$ between realisable site graphs
can be lifted to a morphism between contact maps $g: G \to C$
and $g': G' \to C$ iff the diagram on the right commutes in $\SG$.

Contact maps over $C$ and embeddings form a category $\rSGe_C$.
Composition and the identity arrow
are defined in a similar manner to $\SG$.













%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:

